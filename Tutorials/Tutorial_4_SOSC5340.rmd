---
title:  "SOSC 5340 Tutorial Four"
subtitle: "Instrumental Variable, and Regression Discontinuity"
author: |
  | *Yabin YIN*
  | *HKUST*
date: |
  | *April, 2021*
output: 
  pdf_document:
    number_sections: false
    keep_tex: false
    fig_caption: true
    latex_engine: pdflatex
citecolor: red
fontsize: 8pt
linestretch: 1
geometry: margin=1in
---

# Set working directory to the current directory

```{r eval=FALSE, include=FALSE}
options(tinytex.verbose = TRUE)
# need to install rstudioapi
library(rstudioapi)
# get current directory and set it as working directory
rstudioapi::getActiveDocumentContext
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# clear environment
rm(list = ls())
```

*Remark:* Need to save current R file before using *getActiveDocumentContext*


# R Packages

**R** packages for IV strategy:

- *ivreg*: <https://cran.r-project.org/web/packages/ivreg/index.html>
- *lfe*: <https://cran.r-project.org/web/packages/lfe/index.html>
  - linear models with multiple group fixed effects 
  - deals with many levels of "fixed effect"
  - allows for multi-way clustering s.e.
  - can implement IV estimation
- Read the *reference manual* and *vignettes*.

**R** packages for RD strategy:

- *rdrobust*: <https://cran.r-project.org/web/packages/rdrobust/index.html>
- *rddensity*: <https://cran.r-project.org/web/packages/rddensity/index.html>
- Read the *reference manual* and *vignettes*.
- Other packages for RD: <https://rdpackages.github.io/>


# Instrumental Variable

We will use `ivreg`, `lfe`, and `plm` package to fit instrumental-variable regression by two-stage least squares (2SLS).

Let's use the demand for cigarettes as an example, you can find it in @StockWatson2007 (Chapter 12).


```{r}
# library packages
library(AER)
library(ivreg)

# data processing and transformation
data("CigarettesSW", package = "AER")
?CigarettesSW ## type '?CigarettesSW' to see the introduction of the dataset

## packs: Number of packs per capita
## price: Average price during fiscal year, including sales tax;
## cpi: Consumer price index;
## income: State personal income (total, nominal);
## population: State population;
## tax: Average state, federal and average local excise taxes for fiscal year;
## taxs: Average excise taxes for fiscal year, including sales tax.

CigarettesSW$rprice <- with(CigarettesSW, price/cpi) # real average price
CigarettesSW$rincome <- with(CigarettesSW, income/population/cpi) # real personal income
CigarettesSW$rtax <- with(CigarettesSW, tax/cpi) # real local excise taxes
CigarettesSW$rtdiff <- with(CigarettesSW, (taxs - tax)/cpi) # diff in real local taxes and real taxes

# Estimation
## OLS estimator
ols <- lm(log(packs) ~ log(rprice) + log(rincome), 
          data = CigarettesSW, subset = year == 1995)
ols_se <- coeftest(ols, vcov = vcovHC, type = "HC1")

## Equation 12.15
ivreg_12.15 <- ivreg(log(packs) ~ log(rprice) + log(rincome)| ## 2nd stage
                       log(rincome) + rtdiff, ## 1st stage: rtdiff as IV of rprice
                     data = CigarettesSW,
                     subset = year == 1995)
ivreg_12.15_se <- coeftest(ivreg_12.15, vcov = vcovHC, type = "HC1")

## Equation 12.16
ivreg_12.16 <- ivreg(log(packs) ~ log(rprice) + log(rincome) | 
                       log(rincome) + rtdiff + rtax, ## 1st stage: rtdiff + rtax as IV of rprice
                     data = CigarettesSW,
                     subset = year == 1995)
ivreg_12.16_se <- coeftest(ivreg_12.16, vcov = vcovHC, type = "HC1")

## Show the results
library(texreg)
screenreg(list(ols, ivreg_12.15, ivreg_12.16),
          custom.model.names = c('OLS',"IV_rtdiff", "IV_rtdiff+rtax"),
          custom.coef.names = c("Constant", "log price", "log income per capita"),
          override.se = list(ols_se[,2], ivreg_12.15_se[,2], ivreg_12.16_se[,2]),
          override.pvalues = list(ols_se[,4], ivreg_12.15_se[,4], ivreg_12.16_se[,4]),
          #stars = c(0.1, 0.05, 0.01),
          digits = 4)
# Note: statistical significance level!

```


## Diagnostics: Weak IV and Over-identification test

A good instrumental variable is highly correlated with one or more of the explanatory variables while remaining uncorrelated with the errors.

If an endogenous regressor is only weakly related to the instrumental variables, then its coefficient will be estimated imprecisely. We hope for a large test statistic and small p-value in the diagnostic test for **weak instruments** (Weak instruments: **F-stat > 10**).

Applied to 2SLS regression, the **Wu–Hausman test** is a test of **endogenity**. If all of the regressors are exogenous (*a small test statistics and large p-value*), then both the OLS and 2SLS estimators are consistent, and the OLS estimator is more efficient. But if one or more regressors are endogenous (*a large test statistic and small p-value*), then 2SLS estimator may be better than the OLS estimator.

The **Sargan test** is a test of **overidentification**. When there are more instrumental variables than coefficients to estimate, it’s possible that the instrumental variables provide conflicting information about the values of the coefficients. A large test statistic and small p-value for the Sargan test suggest, therefore, that the model is misspecified. The Sargan test is **inapplicable** to a just-identified regression equation, with an equal number of instrumental variables and coefficients.

```{r}
summary(ivreg_12.15, vcov = vcovHC, diagnostics = TRUE)
summary(ivreg_12.16, vcov = vcovHC, diagnostics = TRUE)
```

## Panel IV

Now, let's use `lfe` and `plm` package to fit a panel IV regression.

```{r}
library(lfe)
library(plm)
felm_12.16 <- felm(log(packs) ~ log(rincome) |
                     0 | # Fixed Effects
                     (log(rprice) ~ rtdiff + rtax) | # Instruments
                     0,
                   data = CigarettesSW,
                   subset = year == 1995)

## Stock and Waston 2007: Table 12.1 Column 1
felm_panel <- felm(log(packs) ~ log(rincome) |
                     year | # Fixed Effects
                     (log(rprice) ~ rtdiff + rtax) | # Instruments
                     0,
                   data = CigarettesSW)

## try `plm`, firstly transform our original data to panel data
CigarettesSW_panel <- pdata.frame(CigarettesSW, index = c("state", "year"), drop.index = TRUE)

## Stock and Waston 2007: Table 12.1 Column 1
plm_within <- plm(log(packs) ~ log(rprice) + log(rincome) | 
                    log(rincome) + rtdiff + rtax, ## IV
             model = c("within"),
             data = CigarettesSW_panel)
plm_within_se <- coeftest(plm_within, vcov. = vcovHC, type='HC1')

screenreg(list(ivreg_12.16, felm_12.16, felm_panel, plm_within),
          override.se = list(ivreg_12.16_se[,2],
                             summary(felm_12.16)$coefficients[,2],
                    summary(felm_panel)$coefficients[,2], plm_within_se[,2]),
          override.pvalues = list(ivreg_12.16_se[,4],
                             summary(felm_12.16)$coefficients[,4],
                    summary(felm_panel)$coefficients[,4], plm_within_se[,4]),
          custom.model.names = c("ivreg 1995", 
                                 "felm 1995",
                                 "felm panel", 
                                 "plm within"),
          digits = 4)
```

**Remark**: How to argue the exogeneity of instruments?

If you suspect that IV impacts on Y through A other than the endogenous variable, then regress A on the IV: will be fine if the result is not significant!


# Regression Discontinuity

We will use `rdrobust` and `rddensity` to deal with RD related analysis.

```{r}
## library packages and load data
library(rdrobust)

## simulated the data
set.seed(3333)
s = 10 + 5*qnorm(runif(10000)) # running variable
x = s - 10 # covariate
w = ifelse(s>10, 1, 0) # treatment: threshold = 10
y1 = 600 + 6.5*x - 2*x^2 + 0.001*x^3 + 300*qnorm(runif(10000)) # treated outcome
y0 = 200 + 6.5*x - 0.20*x^2 + 0.01*x^3 + 300*qnorm(runif(10000)) # control outcome
y  = y0 + w*(y1-y0) # Rubin Causal Model

rd_data <- data.frame(s, x, w, y1, y0, y) 
head(rd_data)
summary(rd_data)

## Step 1: Visualizing outcome discontinuity
attach(rd_data)
rdplot(y=y, x=s, c=10, p=3) 
# y is the dependent variable, x is the running variable, c is the RD cutoff in x; p specifies the order of the global-polynomial used to approximate the population conditional mean functions for control and treated units.
```



```{r}
## Step 2: Testing balancing at the threshold (covariate balance)
rd_data_balance <- subset(rd_data, s>=9 & s<=11) 
t.test(x ~ w, data = rd_data_balance)
## we want to test whether covariate x is balanced in the range [9,11]

## Step 3: Testing non-manipulation of the running variable (bunching of running variable)
plot(density(s))
hist(s, breaks=100)

library(rddensity)
summary(rddensity(s, c=10))
```

Now, let's use `rdrobust` function from `rdrobust` package to estimate ATE. Type `?rdrobust` to see the instruction of the function. Basically, you need to input:

- *y*: the dependent variable;
- *x*: the running variable
- *c*: RD cutoff in x;
- *fuzzy*: specifies the treatment status variable used to implement fuzzy RD estimation;
- *p*: specifies the order of the local-polynomial;
- *h*: specifies the main bandwidth used to construct the RD point estimator. If not specified, bandwidth h is computed by the companion command `rdbwselect`;
- *covs*: specifies additional covariates to be used in the polynomial regression.

```{r}
## Step 4: Estimating ATE by sharp RD
summary(rdrobust(y=y, x=s, c=10, p=3, covs=x))

## Step 5: Checking robustness: varying the bandwidth and the polynomial order
## bandwidth selection
summary(rdbwselect(y, s, c=10, p=3, covs=x))

## varying the bandwidth
summary(rdrobust(y, s, c=10, p=3, h=1, covs=x))
summary(rdrobust(y, s, c=10, p=3, h=5.950, covs=x))
summary(rdrobust(y, s, c=10, p=3, h=10, covs=x))
summary(rdrobust(y, s, c=10, p=3, h=50, covs=x))

## varying the polynomial order
summary(rdrobust(y, s, c=10, p=1, h=5.950, covs=x))
summary(rdrobust(y, s, c=10, p=3, h=5.950, covs=x))
summary(rdrobust(y, s, c=10, p=5, h=5.950, covs=x))
```
